{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPP6mZI7xJxBWeHvLyDz89e"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDvQ09KNkObF",
        "outputId": "5e3c46fe-ffe6-45e5-ca9e-cb77ea6e4417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting pyod\n",
            "  Downloading pyod-2.0.5-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.1 (from gradio)\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pyod) (3.10.0)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.11/dist-packages (from pyod) (0.60.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51->pyod) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyod) (3.2.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyod-2.0.5-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.6/200.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m130.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, groovy, ffmpy, aiofiles, starlette, sounddevice, nvidia-cusparse-cu12, nvidia-cudnn-cu12, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, pyod, gradio, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.31.0 gradio-client-1.10.1 groovy-0.1.2 mediapipe-0.10.21 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-4.25.7 pydub-0.25.1 pyod-2.0.5 python-multipart-0.0.20 ruff-0.11.11 safehttpx-0.1.6 semantic-version-2.10.0 sounddevice-0.5.2 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch gradio sentencepiece scikit-learn tensorflow pyod opencv-python mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "\n",
        "# ==============================================\n",
        "# 1. Personalization & User Profiling\n",
        "# ==============================================\n",
        "\n",
        "class UserProfiler:\n",
        "    def __init__(self):\n",
        "        # Mock user data: [reading_speed, error_rate, preferred_font_size, color_sensitivity]\n",
        "        self.user_data = np.array([\n",
        "            [200, 0.15, 14, 0.7],  # User 1\n",
        "            [180, 0.20, 16, 0.8],    # User 2\n",
        "            [220, 0.10, 12, 0.6],    # User 3\n",
        "            [190, 0.18, 15, 0.75],   # User 4\n",
        "            [210, 0.12, 13, 0.65]    # User 5\n",
        "        ])\n",
        "        self.kmeans = KMeans(n_clusters=3)\n",
        "        self.kmeans.fit(self.user_data)\n",
        "        self.nn = NearestNeighbors(n_neighbors=2)\n",
        "        self.nn.fit(self.user_data)\n",
        "\n",
        "    def get_user_cluster(self, user_features):\n",
        "        \"\"\"Cluster users based on their reading patterns\"\"\"\n",
        "        return self.kmeans.predict([user_features])[0]\n",
        "\n",
        "    def recommend_settings(self, user_features):\n",
        "        \"\"\"Recommend settings based on similar users\"\"\"\n",
        "        _, indices = self.nn.kneighbors([user_features])\n",
        "        similar_users = self.user_data[indices[0]]\n",
        "        return {\n",
        "            'font_size': int(np.mean(similar_users[:, 2])),\n",
        "            'color_scheme': 'dark' if np.mean(similar_users[:, 3]) > 0.7 else 'light',\n",
        "            'reading_speed': int(np.mean(similar_users[:, 0]))\n",
        "        }\n",
        "\n",
        "# ==============================================\n",
        "# 2. Text Processing & Feature Annotation\n",
        "# ==============================================\n",
        "\n",
        "class TextProcessor:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
        "        self.pos_model = pipeline(\"token-classification\",\n",
        "                                model=\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
        "\n",
        "    def annotate_text(self, text):\n",
        "        \"\"\"Annotate text with parts of speech and syllable information\"\"\"\n",
        "        # Get POS tags\n",
        "        pos_result = self.pos_model(text)\n",
        "\n",
        "        # Simple syllable count approximation\n",
        "        words = text.split()\n",
        "        syllable_counts = [self._count_syllables(word) for word in words]\n",
        "\n",
        "        # Phoneme highlighting (simplified)\n",
        "        phonemes = [self._get_phonemes(word) for word in words]\n",
        "\n",
        "        return {\n",
        "            'pos_tags': pos_result,\n",
        "            'syllable_counts': syllable_counts,\n",
        "            'phonemes': phonemes\n",
        "        }\n",
        "\n",
        "    def _count_syllables(self, word):\n",
        "        \"\"\"Approximate syllable count\"\"\"\n",
        "        vowels = \"aeiouy\"\n",
        "        word = word.lower()\n",
        "        count = 0\n",
        "\n",
        "        if word[0] in vowels:\n",
        "            count += 1\n",
        "\n",
        "        for index in range(1, len(word)):\n",
        "            if word[index] in vowels and word[index-1] not in vowels:\n",
        "                count += 1\n",
        "\n",
        "        if word.endswith(\"e\"):\n",
        "            count -= 1\n",
        "\n",
        "        return max(count, 1)\n",
        "\n",
        "    def _get_phonemes(self, word):\n",
        "        \"\"\"Simplified phoneme representation\"\"\"\n",
        "        # In a real system, we'd use a proper phoneme dictionary\n",
        "        phoneme_map = {\n",
        "            'a': 'æ', 'b': 'b', 'c': 'k', 'd': 'd', 'e': 'ɛ',\n",
        "            'f': 'f', 'g': 'g', 'h': 'h', 'i': 'ɪ', 'j': 'dʒ',\n",
        "            'k': 'k', 'l': 'l', 'm': 'm', 'n': 'n', 'o': 'ɔ',\n",
        "            'p': 'p', 'q': 'kw', 'r': 'r', 's': 's', 't': 't',\n",
        "            'u': 'ʌ', 'v': 'v', 'w': 'w', 'x': 'ks', 'y': 'j',\n",
        "            'z': 'z'\n",
        "        }\n",
        "        return [phoneme_map.get(c.lower(), c) for c in word]\n",
        "\n",
        "# ==============================================\n",
        "# 3. Error Prediction & Correction Support\n",
        "# ==============================================\n",
        "\n",
        "from pyod.models.knn import KNN  # Simple alternative\n",
        "\n",
        "class ErrorPredictor:\n",
        "    def __init__(self):\n",
        "        self.common_errors = {\n",
        "            'b': 'd', 'd': 'b', 'p': 'q', 'q': 'p',\n",
        "            'm': 'w', 'w': 'm', 'n': 'u', 'u': 'n',\n",
        "            'was': 'saw', 'on': 'no', 'from': 'form'\n",
        "        }\n",
        "        self.anomaly_detector = KNN(contamination=0.1)\n",
        "\n",
        "    def _build_autoencoder(self):\n",
        "        \"\"\"Build a simple autoencoder for anomaly detection\"\"\"\n",
        "        # Corrected PyOD AutoEncoder initialization\n",
        "        model = AutoEncoder(\n",
        "            epochs_num=50,  # Changed from 'epochs' to 'epochs_num'\n",
        "            contamination=0.1,\n",
        "            verbose=0\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def predict_errors(self, word):\n",
        "        \"\"\"Predict likely dyslexic errors for a word\"\"\"\n",
        "        similar = [v for k, v in self.common_errors.items() if k in word.lower()]\n",
        "        return similar if similar else [\"No common error patterns detected\"]\n",
        "\n",
        "    def detect_anomalies(self, reading_pattern):\n",
        "        \"\"\"Detect anomalies in reading patterns\"\"\"\n",
        "        return self.autoencoder.fit_predict([reading_pattern])[0] == 1\n",
        "\n",
        "# ==============================================\n",
        "# 4. Gaze Tracking & Cognitive Load Estimation\n",
        "# ==============================================\n",
        "\n",
        "class GazeTracker:\n",
        "    def __init__(self):\n",
        "        self.mp_face_mesh = mp.solutions.face_mesh\n",
        "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
        "            max_num_faces=1,\n",
        "            refine_landmarks=True,\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5)\n",
        "\n",
        "        # Simple LSTM model for attention prediction\n",
        "        self.attention_model = self._build_attention_model()\n",
        "\n",
        "    def _build_attention_model(self):\n",
        "        \"\"\"Build a simple LSTM model for attention prediction\"\"\"\n",
        "        model = Sequential([\n",
        "            LSTM(64, input_shape=(10, 2)),  # 10 timesteps, 2 features (x,y)\n",
        "            Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "        # In a real system, we'd train this on actual gaze data\n",
        "        return model\n",
        "\n",
        "    def estimate_attention(self, gaze_points):\n",
        "        \"\"\"Estimate attention level from gaze points\"\"\"\n",
        "        # Preprocess gaze points\n",
        "        seq = np.array(gaze_points[-10:])  # Use last 10 points\n",
        "        if len(seq) < 10:\n",
        "            seq = np.pad(seq, ((0, 10-len(seq)), (0, 0)), 'constant')\n",
        "\n",
        "        # Predict attention (1 = attentive, 0 = distracted)\n",
        "        return self.attention_model.predict(np.expand_dims(seq, 0))[0][0] > 0.5\n",
        "\n",
        "    def process_frame(self, frame):\n",
        "        \"\"\"Process a frame to detect gaze\"\"\"\n",
        "        # Convert to RGB\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.face_mesh.process(frame_rgb)\n",
        "\n",
        "        if results.multi_face_landmarks:\n",
        "            # Get eye landmarks (simplified)\n",
        "            landmarks = results.multi_face_landmarks[0].landmark\n",
        "            left_eye = [landmarks[145], landmarks[159]]  # Example indices\n",
        "            right_eye = [landmarks[374], landmarks[386]] # Example indices\n",
        "\n",
        "            # Calculate simple gaze direction (center between eye points)\n",
        "            gaze_x = (left_eye[0].x + right_eye[0].x) / 2\n",
        "            gaze_y = (left_eye[0].y + right_eye[0].y) / 2\n",
        "\n",
        "            return (gaze_x, gaze_y)\n",
        "        return None\n",
        "\n",
        "# ==============================================\n",
        "# 5. Content Adaptation and Summarization\n",
        "# ==============================================\n",
        "\n",
        "class ContentAdapter:\n",
        "    def __init__(self):\n",
        "        # Load summarization models\n",
        "        self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "        self.simplifier_tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "        self.simplifier_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "    def simplify_text(self, text):\n",
        "        \"\"\"Simplify text using T5 model\"\"\"\n",
        "        input_text = \"simplify: \" + text\n",
        "        inputs = self.simplifier_tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "        outputs = self.simplifier_model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=256,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        return self.simplifier_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    def summarize_text(self, text, summary_type=\"standard\"):\n",
        "        \"\"\"Summarize text with options for different types\"\"\"\n",
        "        if summary_type == \"standard\":\n",
        "            result = self.summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
        "            return result[0]['summary_text']\n",
        "        elif summary_type == \"simplified\":\n",
        "            simplified = self.simplify_text(text)\n",
        "            result = self.summarizer(simplified, max_length=130, min_length=30, do_sample=False)\n",
        "            return result[0]['summary_text']\n",
        "        else:  # bullet points\n",
        "            bullet_prompt = f\"Summarize the following text in bullet points:\\n\\n{text}\"\n",
        "            result = self.summarizer(bullet_prompt, max_length=130, min_length=30, do_sample=False)\n",
        "            return result[0]['summary_text']\n",
        "\n",
        "# ==============================================\n",
        "# Gradio Interface\n",
        "# ==============================================\n",
        "\n",
        "# Initialize components\n",
        "user_profiler = UserProfiler()\n",
        "text_processor = TextProcessor()\n",
        "error_predictor = ErrorPredictor()\n",
        "gaze_tracker = GazeTracker()\n",
        "content_adapter = ContentAdapter()\n",
        "\n",
        "def process_input(text, operation, webcam=None):\n",
        "    \"\"\"Process user input based on selected operation\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    if operation == \"user_profiling\":\n",
        "        # Mock user features: [reading_speed, error_rate, preferred_font_size, color_sensitivity]\n",
        "        user_features = [200, 0.15, 14, 0.7]  # In real system, these would come from actual usage\n",
        "        cluster = user_profiler.get_user_cluster(user_features)\n",
        "        recommendations = user_profiler.recommend_settings(user_features)\n",
        "        results = {\n",
        "            \"User Cluster\": f\"Cluster {cluster}\",\n",
        "            \"Recommended Settings\": recommendations\n",
        "        }\n",
        "\n",
        "    elif operation == \"text_annotation\":\n",
        "        annotation = text_processor.annotate_text(text)\n",
        "        results = {\n",
        "            \"POS Tags\": \"\\n\".join([f\"{tag['word']}: {tag['entity']}\" for tag in annotation['pos_tags']]),\n",
        "            \"Syllable Counts\": \"\\n\".join([f\"{word}: {count}\" for word, count in zip(text.split(), annotation['syllable_counts'])]),\n",
        "            \"Phonemes\": \"\\n\".join([f\"{word}: {' '.join(phonemes)}\" for word, phonemes in zip(text.split(), annotation['phonemes'])])\n",
        "        }\n",
        "\n",
        "    elif operation == \"error_prediction\":\n",
        "        words = text.split()\n",
        "        error_predictions = {}\n",
        "        for word in words[:5]:  # Limit to first 5 words for demo\n",
        "            errors = error_predictor.predict_errors(word)\n",
        "            error_predictions[word] = errors\n",
        "        results = {\"Error Predictions\": \"\\n\".join([f\"{k}: {', '.join(v)}\" for k, v in error_predictions.items()])}\n",
        "\n",
        "    elif operation == \"gaze_tracking\":\n",
        "        if webcam is not None:\n",
        "            # Process webcam frame\n",
        "            frame = cv2.imread(webcam)\n",
        "            gaze_point = gaze_tracker.process_frame(frame)\n",
        "\n",
        "            # Mock gaze points for attention estimation\n",
        "            gaze_points = [(0.5, 0.5) for _ in range(8)]  # First 8 points centered\n",
        "            if gaze_point:\n",
        "                gaze_points.append(gaze_point)\n",
        "\n",
        "            attention = gaze_tracker.estimate_attention(gaze_points)\n",
        "            results = {\n",
        "                \"Gaze Point\": f\"X: {gaze_point[0]:.2f}, Y: {gaze_point[1]:.2f}\" if gaze_point else \"Not detected\",\n",
        "                \"Attention Level\": \"Attentive\" if attention else \"Distracted\"\n",
        "            }\n",
        "        else:\n",
        "            results = {\"Error\": \"No webcam input provided\"}\n",
        "\n",
        "    elif operation == \"content_adaptation\":\n",
        "        simplified = content_adapter.simplify_text(text)\n",
        "        standard_summary = content_adapter.summarize_text(text, \"standard\")\n",
        "        bullet_summary = content_adapter.summarize_text(text, \"bullets\")\n",
        "\n",
        "        results = {\n",
        "            \"Simplified Text\": simplified,\n",
        "            \"Standard Summary\": standard_summary,\n",
        "            \"Bullet Point Summary\": bullet_summary\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Create Gradio interface\n",
        "# Create Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Dyslexia Support System\")\n",
        "\n",
        "    with gr.Tab(\"Main Interface\"):\n",
        "        with gr.Row():\n",
        "            text_input = gr.Textbox(label=\"Input Text\", lines=5)\n",
        "            webcam_input = gr.Image(sources=[\"webcam\"], streaming=True, label=\"Webcam (for gaze tracking)\")\n",
        "\n",
        "        operation = gr.Radio(\n",
        "            choices=[\n",
        "                \"user_profiling\",\n",
        "                \"text_annotation\",\n",
        "                \"error_prediction\",\n",
        "                \"gaze_tracking\",\n",
        "                \"content_adaptation\"\n",
        "            ],\n",
        "            label=\"Select Operation\"\n",
        "        )\n",
        "\n",
        "        submit_btn = gr.Button(\"Process\")\n",
        "\n",
        "        output = gr.JSON(label=\"Results\")\n",
        "\n",
        "        submit_btn.click(\n",
        "            fn=process_input,\n",
        "            inputs=[text_input, operation, webcam_input],\n",
        "            outputs=output\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"About\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## Dyslexia Support System\n",
        "\n",
        "        This system implements five key ML components to support dyslexic readers:\n",
        "\n",
        "        1. **Personalization & User Profiling**: Clusters users and recommends settings\n",
        "        2. **Text Processing & Annotation**: Adds linguistic annotations to text\n",
        "        3. **Error Prediction**: Identifies likely reading errors\n",
        "        4. **Gaze Tracking**: Estimates attention using webcam\n",
        "        5. **Content Adaptation**: Simplifies and summarizes text\n",
        "\n",
        "        Note: This is a demo system with some simplified implementations.\n",
        "        \"\"\")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "_SUWLmcOlNFY",
        "outputId": "afcbd9a9-2045-4807-a08d-7ea6b57488a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4609133411ae79f2a9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4609133411ae79f2a9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}