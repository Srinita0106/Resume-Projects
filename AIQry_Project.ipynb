{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJIm8kyxiqRQ"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import mysql.connector\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datetime import datetime, timedelta\n",
        "import graphviz\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sql_metadata import Parser\n",
        "\n",
        "# Set page config must be the first Streamlit command\n",
        "st.set_page_config(page_title=\"Semantic SQL Search\", layout=\"wide\")\n",
        "\n",
        "# Initialize local sentence transformer model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "# Database connection\n",
        "def connect_to_db(db_name=None):\n",
        "    return mysql.connector.connect(\n",
        "        host=\"localhost\",\n",
        "        user=\"root\",\n",
        "        password=\"root2003\",\n",
        "        database=db_name\n",
        "    )\n",
        "\n",
        "# Get list of available databases\n",
        "@st.cache_data\n",
        "def get_available_databases():\n",
        "    try:\n",
        "        conn = mysql.connector.connect(\n",
        "            host=\"localhost\",\n",
        "            user=\"root\",\n",
        "            password=\"root2003\"\n",
        "        )\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SHOW DATABASES\")\n",
        "        databases = [db[0] for db in cursor.fetchall() if db[0] not in ('information_schema', 'mysql', 'performance_schema', 'sys')]\n",
        "        cursor.close()\n",
        "        conn.close()\n",
        "        return databases\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error connecting to MySQL: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Schema understanding\n",
        "@st.cache_data(ttl=3600)\n",
        "def get_schema_info(db_name):\n",
        "    conn = connect_to_db(db_name)\n",
        "    cursor = conn.cursor(dictionary=True)\n",
        "\n",
        "    cursor.execute(\"SHOW TABLES\")\n",
        "    tables = [list(table.values())[0] for table in cursor.fetchall()]\n",
        "\n",
        "    schema_info = {\"tables\": {}, \"relationships\": [], \"database\": db_name}\n",
        "\n",
        "    for table in tables:\n",
        "        cursor.execute(f\"DESCRIBE {table}\")\n",
        "        columns = cursor.fetchall()\n",
        "\n",
        "        cursor.execute(f\"SELECT * FROM {table} LIMIT 1\")\n",
        "        sample = cursor.fetchone()\n",
        "\n",
        "        schema_info[\"tables\"][table] = {\n",
        "            \"columns\": [col['Field'] for col in columns],\n",
        "            \"types\": {col['Field']: col['Type'] for col in columns},\n",
        "            \"sample\": sample\n",
        "        }\n",
        "\n",
        "    # Get foreign keys\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT TABLE_NAME, COLUMN_NAME, REFERENCED_TABLE_NAME, REFERENCED_COLUMN_NAME\n",
        "        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE\n",
        "        WHERE REFERENCED_TABLE_NAME IS NOT NULL\n",
        "        AND TABLE_SCHEMA = DATABASE()\n",
        "    \"\"\")\n",
        "    schema_info[\"relationships\"] = cursor.fetchall()\n",
        "\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    return schema_info\n",
        "\n",
        "# Create schema embeddings\n",
        "@st.cache_data\n",
        "def create_schema_embeddings(schema_info):\n",
        "    embeddings = {}\n",
        "    for table, info in schema_info[\"tables\"].items():\n",
        "        # Embed table name and description\n",
        "        table_desc = f\"{table} table with columns: {', '.join(info['columns'])}\"\n",
        "        table_embedding = model.encode(table_desc)\n",
        "\n",
        "        # Embed column names with their types\n",
        "        column_embeddings = {}\n",
        "        for column in info['columns']:\n",
        "            col_desc = f\"{column} ({info['types'][column]})\"\n",
        "            column_embeddings[column] = model.encode(col_desc)\n",
        "\n",
        "        embeddings[table] = {\n",
        "            \"table_embedding\": table_embedding,\n",
        "            \"columns\": column_embeddings\n",
        "        }\n",
        "    return embeddings\n",
        "\n",
        "# Find closest schema matches\n",
        "def find_schema_matches(query, schema_info, schema_embeddings):\n",
        "    query_embedding = model.encode(query)\n",
        "\n",
        "    # Find closest table\n",
        "    table_scores = []\n",
        "    for table, embeddings in schema_embeddings.items():\n",
        "        similarity = np.dot(query_embedding, embeddings[\"table_embedding\"])\n",
        "        table_scores.append((table, similarity))\n",
        "\n",
        "    # Sort by similarity score\n",
        "    table_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    best_table = table_scores[0][0]\n",
        "\n",
        "    # Find closest columns\n",
        "    column_scores = []\n",
        "    for column, embedding in schema_embeddings[best_table][\"columns\"].items():\n",
        "        similarity = np.dot(query_embedding, embedding)\n",
        "        column_scores.append((column, similarity))\n",
        "\n",
        "    column_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return best_table, [col[0] for col in column_scores[:5]]  # return top 5 columns\n",
        "\n",
        "# Rule-based SQL generator\n",
        "def generate_sql(query, schema_info, schema_embeddings):\n",
        "    table, columns = find_schema_matches(query, schema_info, schema_embeddings)\n",
        "\n",
        "    # Basic query construction\n",
        "    select_columns = \", \".join(columns)\n",
        "\n",
        "    # Simple condition detection\n",
        "    conditions = []\n",
        "\n",
        "    # Time-related conditions\n",
        "    time_phrases = {\n",
        "        \"last week\": \">= DATE_SUB(CURDATE(), INTERVAL 1 WEEK)\",\n",
        "        \"last month\": \">= DATE_SUB(CURDATE(), INTERVAL 1 MONTH)\",\n",
        "        \"last year\": \">= DATE_SUB(CURDATE(), INTERVAL 1 YEAR)\",\n",
        "        \"today\": \"= CURDATE()\"\n",
        "    }\n",
        "\n",
        "    date_column = None\n",
        "    for col in columns:\n",
        "        if \"date\" in col.lower() or \"time\" in col.lower():\n",
        "            date_column = col\n",
        "            break\n",
        "\n",
        "    for phrase, sql_phrase in time_phrases.items():\n",
        "        if phrase in query.lower() and date_column:\n",
        "            conditions.append(f\"{date_column} {sql_phrase}\")\n",
        "\n",
        "    # Negation detection\n",
        "    negation_words = [\"not\", \"didn't\", \"haven't\", \"hasn't\", \"no\"]\n",
        "    for word in negation_words:\n",
        "        if word in query.lower():\n",
        "            # Find the verb after negation\n",
        "            query_lower = query.lower()\n",
        "            neg_index = query_lower.find(word)\n",
        "            next_word = query_lower[neg_index:].split()[1] if len(query_lower[neg_index:].split()) > 1 else \"\"\n",
        "\n",
        "            # Map to possible column names\n",
        "            for col in columns:\n",
        "                if next_word in col.lower():\n",
        "                    conditions.append(f\"{col} IS NULL OR {col} = 0\")\n",
        "                    break\n",
        "\n",
        "    # Basic number filters\n",
        "    number_words = [\"more than\", \"greater than\", \"over\", \"less than\", \"under\"]\n",
        "    for word in number_words:\n",
        "        if word in query.lower():\n",
        "            # Try to extract the number\n",
        "            parts = query.lower().split(word)\n",
        "            if len(parts) > 1:\n",
        "                num_part = parts[1].strip().split()[0]\n",
        "                if num_part.replace('.', '').isdigit():\n",
        "                    for col in columns:\n",
        "                        if \"amount\" in col.lower() or \"price\" in col.lower() or \"total\" in col.lower():\n",
        "                            operator = \">\" if word in [\"more than\", \"greater than\", \"over\"] else \"<\"\n",
        "                            conditions.append(f\"{col} {operator} {num_part}\")\n",
        "                            break\n",
        "\n",
        "    # Build WHERE clause\n",
        "    where_clause = \"\"\n",
        "    if conditions:\n",
        "        where_clause = \"WHERE \" + \" AND \".join(conditions)\n",
        "\n",
        "    # Basic SQL generation\n",
        "    sql = f\"SELECT {select_columns} FROM {table} {where_clause} LIMIT 100\"\n",
        "\n",
        "    return sql\n",
        "\n",
        "# Create schema diagram\n",
        "def create_schema_diagram(schema_info):\n",
        "    graph = graphviz.Digraph()\n",
        "\n",
        "    # Add tables as nodes\n",
        "    for table_name, table_info in schema_info[\"tables\"].items():\n",
        "        columns = \"\\l\".join([f\"{col} ({table_info['types'][col]})\" for col in table_info[\"columns\"]])\n",
        "        graph.node(table_name, f\"{table_name}\\l{columns}\", shape=\"box\")\n",
        "\n",
        "    # Add relationships as edges\n",
        "    for rel in schema_info[\"relationships\"]:\n",
        "        graph.edge(\n",
        "            rel[\"TABLE_NAME\"],\n",
        "            rel[\"REFERENCED_TABLE_NAME\"],\n",
        "            label=f\"{rel['COLUMN_NAME']} ‚Üí {rel['REFERENCED_COLUMN_NAME']}\"\n",
        "        )\n",
        "\n",
        "    return graph\n",
        "\n",
        "# Create ER diagram\n",
        "def create_er_diagram(schema_info):\n",
        "    graph = graphviz.Digraph(engine='neato', graph_attr={'splines': 'ortho'})\n",
        "\n",
        "    # Add tables as nodes\n",
        "    for table_name, table_info in schema_info[\"tables\"].items():\n",
        "        # Identify primary keys\n",
        "        pk_columns = [col for col in table_info[\"columns\"]\n",
        "                     if \"PRIMARY\" in str(table_info[\"types\"][col]).upper()]\n",
        "\n",
        "        # Format columns with PK indicators\n",
        "        columns = []\n",
        "        for col in table_info[\"columns\"]:\n",
        "            col_str = f\"*{col}*\" if col in pk_columns else col\n",
        "            columns.append(f\"{col_str} ({table_info['types'][col]})\")\n",
        "\n",
        "        columns_str = \"\\l\".join(columns)\n",
        "        graph.node(table_name, f\"<<b>{table_name}</b>>\\l{columns_str}\", shape=\"none\")\n",
        "\n",
        "    # Add relationships as edges\n",
        "    for rel in schema_info[\"relationships\"]:\n",
        "        graph.edge(\n",
        "            rel[\"TABLE_NAME\"],\n",
        "            rel[\"REFERENCED_TABLE_NAME\"],\n",
        "            label=f\"{rel['COLUMN_NAME']} ‚Üí {rel['REFERENCED_COLUMN_NAME']}\",\n",
        "            dir=\"both\",\n",
        "            arrowtail=\"crow\",\n",
        "            arrowhead=\"none\"\n",
        "        )\n",
        "\n",
        "    return graph\n",
        "\n",
        "# Generate visualizations based on query results\n",
        "def generate_visualizations(df, sql_query):\n",
        "    try:\n",
        "        # Parse SQL to understand what was selected\n",
        "        parsed = Parser(sql_query)\n",
        "        selected_columns = parsed.columns_dict.get(\"select\", [])\n",
        "\n",
        "        # Remove table prefixes if they exist\n",
        "        clean_columns = [col.split('.')[-1].strip('`') for col in selected_columns]\n",
        "\n",
        "        # Create tabs for different visualization types\n",
        "        tab1, tab2, tab3, tab4 = st.tabs([\"üìä Summary\", \"üìà Line Chart\", \"üç© Pie Chart\", \"üìã Data Table\"])\n",
        "\n",
        "        with tab1:\n",
        "            st.subheader(\"Data Summary\")\n",
        "            st.write(df.describe(include='all'))\n",
        "\n",
        "            # Auto-detect numeric columns for histogram\n",
        "            numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "            if len(numeric_cols) > 0:\n",
        "                selected_num_col = st.selectbox(\"Select numeric column for histogram\", numeric_cols)\n",
        "                fig = px.histogram(df, x=selected_num_col, title=f\"Distribution of {selected_num_col}\")\n",
        "                st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "        with tab2:\n",
        "            st.subheader(\"Line Chart\")\n",
        "            # Try to find date/time columns\n",
        "            date_cols = [col for col in df.columns if any(term in str(col).lower() for term in ['date', 'time', 'year', 'month', 'day'])]\n",
        "\n",
        "            if len(date_cols) > 0:\n",
        "                date_col = st.selectbox(\"Select date column\", date_cols)\n",
        "                value_col = st.selectbox(\"Select value column\", [col for col in df.columns if col != date_col])\n",
        "\n",
        "                if st.button(\"Generate Line Chart\"):\n",
        "                    try:\n",
        "                        df[date_col] = pd.to_datetime(df[date_col])\n",
        "                        fig = px.line(df.sort_values(date_col), x=date_col, y=value_col,\n",
        "                                      title=f\"{value_col} over Time\")\n",
        "                        st.plotly_chart(fig, use_container_width=True)\n",
        "                    except Exception as e:\n",
        "                        st.warning(f\"Couldn't create line chart: {str(e)}\")\n",
        "            else:\n",
        "                st.warning(\"No date/time columns found for line chart\")\n",
        "\n",
        "        with tab3:\n",
        "            st.subheader(\"Pie Chart\")\n",
        "            # Try to find categorical columns\n",
        "            cat_cols = [col for col in df.columns if len(df[col].unique()) <= 20 and len(df[col].unique()) > 1]\n",
        "\n",
        "            if len(cat_cols) > 0:\n",
        "                cat_col = st.selectbox(\"Select categorical column\", cat_cols)\n",
        "\n",
        "                if st.button(\"Generate Pie Chart\"):\n",
        "                    fig = px.pie(df, names=cat_col, title=f\"Distribution of {cat_col}\")\n",
        "                    st.plotly_chart(fig, use_container_width=True)\n",
        "            else:\n",
        "                st.warning(\"No suitable categorical columns found for pie chart\")\n",
        "\n",
        "        with tab4:\n",
        "            st.subheader(\"Detailed Data View\")\n",
        "            st.dataframe(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error generating visualizations: {str(e)}\")\n",
        "\n",
        "# Main app function\n",
        "def main():\n",
        "    st.title(\"üîç Enhanced Semantic SQL Search Engine\")\n",
        "    st.write(\"Ask your database questions in plain English - no API keys required\")\n",
        "\n",
        "    # Database selection\n",
        "    available_dbs = get_available_databases()\n",
        "    selected_db = st.selectbox(\"Select Database\", available_dbs)\n",
        "\n",
        "    if not selected_db:\n",
        "        st.warning(\"Please select a database to continue\")\n",
        "        return\n",
        "\n",
        "    # Initialize session state\n",
        "    if 'schema_info' not in st.session_state or st.session_state.schema_info.get(\"database\") != selected_db:\n",
        "        with st.spinner(f\"Loading {selected_db} schema...\"):\n",
        "            st.session_state.schema_info = get_schema_info(selected_db)\n",
        "            st.session_state.schema_embeddings = create_schema_embeddings(st.session_state.schema_info)\n",
        "\n",
        "    # Schema visualization tabs\n",
        "    tab1, tab2, tab3 = st.tabs([\"üóÉÔ∏è Schema Browser\", \"üìê Schema Diagram\", \"üîó ER Diagram\"])\n",
        "\n",
        "    with tab1:\n",
        "        # Sidebar with schema info\n",
        "        with st.sidebar:\n",
        "            st.subheader(\"Database Schema\")\n",
        "            selected_table = st.selectbox(\"Select table\", list(st.session_state.schema_info[\"tables\"].keys()))\n",
        "\n",
        "            if selected_table:\n",
        "                st.write(f\"**Columns in {selected_table}:**\")\n",
        "                for col in st.session_state.schema_info[\"tables\"][selected_table][\"columns\"]:\n",
        "                    st.write(f\"- {col} ({st.session_state.schema_info['tables'][selected_table]['types'][col]})\")\n",
        "\n",
        "                st.write(\"**Sample row:**\")\n",
        "                st.json(st.session_state.schema_info[\"tables\"][selected_table][\"sample\"])\n",
        "\n",
        "    with tab2:\n",
        "        st.subheader(\"Database Schema Diagram\")\n",
        "        schema_graph = create_schema_diagram(st.session_state.schema_info)\n",
        "        st.graphviz_chart(schema_graph)\n",
        "\n",
        "    with tab3:\n",
        "        st.subheader(\"Entity Relationship Diagram\")\n",
        "        er_graph = create_er_diagram(st.session_state.schema_info)\n",
        "        st.graphviz_chart(er_graph)\n",
        "\n",
        "    # Main query interface\n",
        "    st.divider()\n",
        "    query = st.text_input(\n",
        "        \"Ask your database question:\",\n",
        "        placeholder=\"e.g., Show me customers who bought in the last month but didn't open our emails\",\n",
        "        key=\"query_input\"\n",
        "    )\n",
        "\n",
        "    col1, col2 = st.columns([3, 1])\n",
        "    with col1:\n",
        "        if st.button(\"Generate SQL\", type=\"primary\"):\n",
        "            if query:\n",
        "                with st.spinner(\"Generating SQL query...\"):\n",
        "                    try:\n",
        "                        sql_query = generate_sql(query, st.session_state.schema_info, st.session_state.schema_embeddings)\n",
        "                        st.session_state.generated_sql = sql_query\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Error generating SQL: {str(e)}\")\n",
        "            else:\n",
        "                st.warning(\"Please enter a question\")\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"Clear\"):\n",
        "            st.session_state.pop(\"generated_sql\", None)\n",
        "            st.experimental_rerun()\n",
        "\n",
        "    if 'generated_sql' in st.session_state:\n",
        "        st.subheader(\"Generated SQL\")\n",
        "        st.code(st.session_state.generated_sql, language=\"sql\")\n",
        "\n",
        "        if st.button(\"Execute Query\"):\n",
        "            try:\n",
        "                conn = connect_to_db(selected_db)\n",
        "                df = pd.read_sql(st.session_state.generated_sql, conn)\n",
        "\n",
        "                st.subheader(f\"Results ({len(df)} rows)\")\n",
        "\n",
        "                # Generate visualizations\n",
        "                generate_visualizations(df, st.session_state.generated_sql)\n",
        "\n",
        "                # Export options\n",
        "                csv = df.to_csv(index=False).encode('utf-8')\n",
        "                st.download_button(\n",
        "                    \"Download as CSV\",\n",
        "                    data=csv,\n",
        "                    file_name=f\"query_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                    mime='text/csv'\n",
        "                )\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error executing query: {str(e)}\")\n",
        "            finally:\n",
        "                if 'conn' in locals():\n",
        "                    conn.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}
